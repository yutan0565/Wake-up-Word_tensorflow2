{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wake_up_word_all",
      "provenance": [],
      "collapsed_sections": [
        "XVQZDw7giaeS",
        "SeQMo6BUPpHn"
      ],
      "mount_file_id": "1V3vMmYINqXBZajvEXLv_9LdNh_6e2wIN",
      "authorship_tag": "ABX9TyNDYLFa4VOdRPa2dkC4xL9I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yutan0565/Wake-up-Word_tensorflow2/blob/main/Wake_up_word_all.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python_speech_features\n",
        "!pip install playsound\n",
        "!pip install -q tensorflow-model-optimization\n",
        "#!pip install pyaudio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFceqLTOE0ZZ",
        "outputId": "246d14c1-9604-4087-87cb-f698a4823cbc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python_speech_features in /usr/local/lib/python3.7/dist-packages (0.6)\n",
            "Requirement already satisfied: playsound in /usr/local/lib/python3.7/dist-packages (1.3.0)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 학습 준비"
      ],
      "metadata": {
        "id": "eL10wX1siLGx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "LaIMW3_FdLEV"
      },
      "outputs": [],
      "source": [
        "from os import listdir\n",
        "from os.path import isdir, join\n",
        "import librosa\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import python_speech_features\n",
        "from playsound import playsound\n",
        "\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger, TensorBoard\n",
        "import tensorflow_model_optimization as tfmot\n",
        "from tensorflow import lite\n",
        "\n",
        "base_path = \"/content/drive/MyDrive/\"\n",
        "#base_path = \"./\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MFCC 추출 해주기\n",
        "# https://blog.naver.com/PostView.nhn?isHttpsRedirect=true&blogId=sooftware&logNo=221661644808 참고\n",
        "def get_librosa_mfcc(filepath):\n",
        "  samplie_rate = 8000\n",
        "  sig, sr = librosa.core.load(filepath, samplie_rate)\n",
        "\n",
        "  # log mell 찾아 보기\n",
        "  # 120 만큼은 겹치게 된다.\n",
        "  mfccs = librosa.feature.mfcc(y = sig, sr = sr, hop_length =200, n_mfcc = 40, n_fft = 320 )\n",
        "  return mfccs\n",
        "\n",
        "num_mfcc = 40\n",
        "len_mfcc = 40\n",
        "\n",
        "\n",
        "# n_mfcc : 음성데이터를 어느 단위로 쪼갤지 (사람은 20 ~ 40 ms 까지는 음소가 바뀌지 못함 - 말 자르는 가장 작은 단위 == frame_size\n",
        "# n_fft : frame의 length = window size,   잘린 음석이 n_ftt보다 작으면 0으로 Padding 해줌, \n",
        "   #n_fft는 winddow size보다 크거나 같아야함\n",
        "   # n_ftt = 8000 * 0.040 = 320\n",
        "# hop_legth : window 얼마 만큼씩 움질일 것인가\n",
        "\n",
        "  # n_mfcc = 40\n",
        "  # hop_length = 200  # 8000 * 0.040\n",
        "  # N_FFT = 320    # 8000 * 0.040\n",
        "\n",
        "# 이거 기준으로 나눈 다음에 Mel값을 뽑아서 Feature로 사용하게 된다.  (  50%는 겹치게 분할을 진행)\n",
        "# 각각의 frame에 대해서 Hamming Window 적용해서 연속성 맞춰주기 - Default 설정임\n",
        "# 각 프레임에 대하여 Fourier Transform 적용해서(FFT) 주파서 성분 알아내기\n",
        "# Mel Filter Banb(삶귀처럼, 주파수 증가할수록 큰 삼각형 filter가 생각다고 생각하기)\n",
        "# 여기까지하면 Mel-Spectrogram Feature가 추출된다.\n",
        "\n",
        "# Mel-Spectrogram 을 압축해서 표현해주는 DCT 연산 수행 -> Discrete Cosine Transform\n"
      ],
      "metadata": {
        "id": "RwAiwzW6oNC4"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터가 저장되어 있는 경로 ( class 별로 묶여 있는 곳)\n",
        "dataset_path = base_path + 'custum_dataset'\n",
        "print(dataset_path)\n",
        "\n",
        "# 폴더 안에 들어 있는 폴더명(class 이름 확인)\n",
        "for name in listdir(dataset_path): \n",
        "  if isdir( \"/\".join( [dataset_path,name ])) :  # 폴더가 존재 한다면\n",
        "    print(name)\n",
        "\n",
        "# 폴더명 = target ,  target이 들어가 있는 list 생성\n",
        "target_list = [ name for name in listdir(dataset_path) if isdir(\"/\".join( [dataset_path,name ]))]\n",
        "target_list.remove('_background_noise_')  # 배경음 제거 해주기\n",
        "print(target_list)\n",
        "\n",
        "# filname, 을 쪽 모아서,\n",
        "filenames = []\n",
        "y = []\n",
        "for index, target in enumerate(target_list):\n",
        "    print('/'.join([dataset_path, target]))  # class 에 맞는 폴더 이름 넣어주기\n",
        "    filenames.append(listdir('/'.join([dataset_path, target])))\n",
        "    y.append(np.ones(len(filenames[index])) * index) \n",
        "\n",
        "# 하나로 쭉 나열 하기\n",
        "filenames = [item for sublist in filenames for item in sublist]\n",
        "y = [item for sublist in y for item in sublist]\n",
        "\n",
        "# file 모아둔거 한번 섞어 주기\n",
        "filenames_y = list(zip(filenames, y))\n",
        "random.shuffle(filenames_y)\n",
        "filenames, y = zip(*filenames_y)\n",
        "\n",
        "# train, valid, test 나눠 주기\n",
        "val_ratio = 0.1\n",
        "test_ratio = 0.2\n",
        "\n",
        "val_set_size = int(len(filenames) * val_ratio)\n",
        "test_set_size = int(len(filenames) * test_ratio)\n",
        "\n",
        "filenames_val = filenames[:val_set_size]\n",
        "filenames_test = filenames[val_set_size:(val_set_size + test_set_size)]\n",
        "filenames_train = filenames[(val_set_size + test_set_size):]\n",
        "\n",
        "y_val = y[:val_set_size]\n",
        "y_test = y[val_set_size:(val_set_size + test_set_size)]\n",
        "y_train = y[(val_set_size + test_set_size):]\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "iigZ1Z0diKbl",
        "outputId": "0cb0ca6b-8a24-407a-b0bb-ecce4a39c67e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/custum_dataset\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-2998941bdf24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 폴더 안에 들어 있는 폴더명(class 이름 확인)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m  \u001b[0;31m# 폴더가 존재 한다면\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/custum_dataset'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# wav 파일 있는 경로가 들어오면, \n",
        "def get_librosa_mfcc(filepath):\n",
        "  samplie_rate = 8000\n",
        "  sig, sr = librosa.core.load(filepath, samplie_rate)\n",
        "  mfccs = librosa.feature.mfcc(y = sig, sr = sr, hop_length =200, n_mfcc = 40, n_fft = 320 )\n",
        "  return mfccs"
      ],
      "metadata": {
        "id": "a7aOfxFvoM_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 지금 내가 가지고 있는 것을 다 변환 했을때  동일한 크기의 mfcc 파일이 나오는가, 이상한거는 버려주기\n",
        "prob_cnt = 0  \n",
        "x_test = []\n",
        "y_test = []\n",
        "for index, filename in enumerate(filenames_train):\n",
        "    \n",
        "    # Stop after 500\n",
        "    if index >= 500:\n",
        "        break\n",
        "    \n",
        "    # Create path from given filename and target item\n",
        "    path = join(dataset_path, target_list[int(y_train[index])], \n",
        "                filename)\n",
        "    \n",
        "    # Create MFCCs\n",
        "    mfccs = get_librosa_mfcc(path)\n",
        "    \n",
        "    if mfccs.shape[1] == len_mfcc:    # 지금은 40으로 설정되어 있음, ///  길이가 부족하면 나중에 버려야함\n",
        "        x_test.append(mfccs)\n",
        "        y_test.append(y_train[index])\n",
        "    else:\n",
        "        print('Dropped:', index, mfccs.shape)\n",
        "        prob_cnt += 1\n",
        "print('% of problematic samples:', prob_cnt / 500)"
      ],
      "metadata": {
        "id": "Ir7V_q_VoNFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 내가 확인 할 부분\n",
        "idx = 1\n",
        "\n",
        "# Create path from given filename and target item\n",
        "path = '/'.join([dataset_path, target_list[int(y_train[idx])], \n",
        "            filenames_train[idx]])\n",
        "\n",
        "# mfcc 만들기\n",
        "mfccs = get_librosa_mfcc(path)\n",
        "print(\"MFCCs:\", mfccs)\n",
        "\n",
        "# MFCC 그림으로 보기\n",
        "fig = plt.figure()\n",
        "plt.imshow(mfccs, cmap='inferno', origin='lower')\n",
        "\n",
        "# 소리 확인\n",
        "print(target_list[int(y_train[idx])])\n",
        "print(path)\n",
        "playsound(path)"
      ],
      "metadata": {
        "id": "ImVwh1C9EDv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 하기 전에 미리 모든 소리에 대해서 feature 추출해서 준비 해두는 단계, inpu을 맞추려고 \n",
        "def extract_features(in_files, in_y):\n",
        "    prob_cnt = 0\n",
        "    out_x = []\n",
        "    out_y = []\n",
        "        \n",
        "    for index, filename in enumerate(in_files):\n",
        "    \n",
        "        # Create path from given filename and target item\n",
        "        path = join(dataset_path, target_list[int(in_y[index])], \n",
        "                    filename)\n",
        "        \n",
        "        # Check to make sure we're reading a .wav file\n",
        "        if not path.endswith('.wav'):\n",
        "            continue\n",
        "\n",
        "        # Create MFCCs\n",
        "        mfccs = get_librosa_mfcc(path)\n",
        "        print(mfccs.shape)\n",
        "\n",
        "        if mfccs.shape[1] == len_mfcc:\n",
        "            out_x.append(mfccs)\n",
        "            out_y.append(in_y[index])\n",
        "        else:\n",
        "            print('Dropped:', index, mfccs.shape)\n",
        "            prob_cnt += 1\n",
        "            \n",
        "    return out_x, out_y, prob_cnt"
      ],
      "metadata": {
        "id": "2O53qDlmF6pp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train, prob_train = extract_features(filenames_train, y_train)\n",
        "x_val, y_val, prob_val = extract_features(filenames_val, y_val)\n",
        "x_test, y_test, prob_test = extract_features(filenames_test, y_test)\n",
        "\n",
        "print(\"Train 잃은거{}\".format(prob_train / len(y_train)))\n",
        "print(\"Valid 잃은거{}\".format(prob_valid / len(y_valid)))\n",
        "print(\"Test 잃은거{}\".format(prob_test / len(y_test)))"
      ],
      "metadata": {
        "id": "TVOZN9PqGHe9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습에 사용할 모든 - MFCC 까지 모두 진행한 정보들\n",
        "#저장 할 곳\n",
        "np.savez(\"./mfcc_set.npz\", \n",
        "         x_train=x_train, \n",
        "         y_train=y_train, \n",
        "         x_val=x_val, \n",
        "         y_val=y_val, \n",
        "         x_test=x_test, \n",
        "         y_test=y_test)"
      ],
      "metadata": {
        "id": "BFEyc1kIG2oC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 학습"
      ],
      "metadata": {
        "id": "XVQZDw7giaeS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 나중에 저장할 모델 - 2진 분류\n",
        "model_filename = 'hi_yutan_original_model.h5'\n",
        "wake_word = 'hi_yutan'\n",
        "feature_sets = np.load( base_path + \"mfcc_set.npz\")\n",
        "\n",
        "# 저장되어 있는 mfcc feature 들 불러 오기\n",
        "x_train = feature_sets['x_train']\n",
        "y_train = feature_sets['y_train']\n",
        "x_val = feature_sets['x_val']\n",
        "y_val = feature_sets['y_val']\n",
        "x_test = feature_sets['x_test']\n",
        "y_test = feature_sets['y_test']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "UORwgpYuFs3a",
        "outputId": "916b60f5-4a5f-48d5-8de7-1c98daf7477b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-7050d6c6eeb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'hi_yutan_original_model.h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mwake_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'hi_yutan'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfeature_sets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./mfcc_set.npz\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# 저장되어 있는 mfcc feature 들 불러 오기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './mfcc_set.npz'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(x_val.shape)\n",
        "print(x_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "iOdWs4rVoNX-",
        "outputId": "52a9eae8-a96b-4e60-a663-b856a489dbe3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-d230d893de68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 내가 수행 하고 싶은 \"기동어\" 설정\n",
        "# index (나는 하나니까 0) 이면, True 또는 False 반환 해주기 - 1아니면 0 ]\n",
        "wake_word_index = all_targets.index(wake_word)\n",
        "y_train = np.equal(y_train, wake_word_index).astype('float64')\n",
        "y_val = np.equal(y_val, wake_word_index).astype('float64')\n",
        "y_test = np.equal(y_test, wake_word_index).astype('float64')"
      ],
      "metadata": {
        "id": "gNjK8_proNIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN 에 넣기 이전에 Channel을 1로 만들어주기\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], \n",
        "                          x_train.shape[1], \n",
        "                          x_train.shape[2], \n",
        "                          1)\n",
        "x_val = x_val.reshape(x_val.shape[0], \n",
        "                      x_val.shape[1], \n",
        "                      x_val.shape[2], \n",
        "                      1)\n",
        "x_test = x_test.reshape(x_test.shape[0], \n",
        "                        x_test.shape[1], \n",
        "                        x_test.shape[2], \n",
        "                        1)\n",
        "print(x_train.shape)\n",
        "print(x_val.shape)\n",
        "print(x_test.shape)\n",
        "\n",
        "sample_shape = x_test.shape[1:]\n",
        "print(sample_shape)"
      ],
      "metadata": {
        "id": "eFsT1UyyoNbG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 Conv-layer \n",
        "conv_layer = keras.Sequential([\n",
        "                             layers.Conv2D(32, (2,2), activation = 'relu', input_shape = sample_shape),\n",
        "                             layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "                             layers.Conv2D(32, (2, 2), activation='relu'),\n",
        "                             layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "                             layers.Conv2D(64, (2, 2), activation='relu'),\n",
        "                             layers.MaxPooling2D(pool_size=(2, 2))\n",
        "                             ])\n",
        "# FC layer는 다른거 사용   --  Class 10 개 분류\n",
        "fc_layer = keras.Sequential([\n",
        "                             layers.Flatten(),\n",
        "                             layers.Dense(64, activation = 'relu'),\n",
        "                             layers.Dropout(0.5),\n",
        "                             layers.Dense(1, activation = \"sigmoid\")\n",
        "                             ])\n",
        "\n",
        "model = keras.Sequential([conv_layer,\n",
        "                          fc_layer\n",
        "                          ])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "TllWIRQ8NHt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Callback 함수 지정 해주기      학습하는 동안 설정해줄것\n",
        "early_stop = EarlyStopping(patience=30) \n",
        "mc = ModelCheckpoint(base_path + \"best_model/wake_up_word_model\", \n",
        "                     save_best_only=True,\n",
        "                     monitor = 'val_loss',\n",
        "                     verbose = 1,\n",
        "                     mode = 'min') \n",
        "reduce_lr  = ReduceLROnPlateau(monitor = 'val_loss',\n",
        "                               factor=0.5, \n",
        "                               patience=5\n",
        "                               ) \n",
        "\n",
        "#optimizer 조정 해주기\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)"
      ],
      "metadata": {
        "id": "wnQ9lmkPOWzo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer, loss 함수를 정의하고,  학습 준비를 한다,  metrics 는 어떤 일이 발생하는지 보여줄 것들\n",
        "model.compile(optimizer=opt, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# 한번에 몇개의 데이터 학습하고 가중치 갱신할지 \n",
        "history = model.fit(train_x, train_y,\n",
        "          epochs=100,\n",
        "          verbose=1,\n",
        "          batch_size=32,\n",
        "          #validation_split = 0.1\n",
        "          validation_data = (valid_x, valid_y),\n",
        "          callbacks = [early_stop, reduce_lr , mc]\n",
        "          )"
      ],
      "metadata": {
        "id": "znxHqYi_OW55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 과정 점검 하기\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QGP-e_TnOW8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, y in enumerate(y_test):\n",
        "    if y == 1:\n",
        "        print(idx)"
      ],
      "metadata": {
        "id": "YliEVeZhO3TU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습한거에서 test 어떻게 나오는지 확인 해보기\n",
        "model = tf.keras.models.load_model(base_path + 'best_model/wake_up_word_model')\n",
        "for i in range(1, 2):\n",
        "    print('Answer:', y_test[i], ' Prediction:', model.predict(np.expand_dims(x_test[i], 0)))"
      ],
      "metadata": {
        "id": "dz9_EYVFPWya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x=x_test, y=y_test)"
      ],
      "metadata": {
        "id": "pvyb-5m8PldX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# tflite 변환 해주기"
      ],
      "metadata": {
        "id": "SeQMo6BUPpHn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tflite_filename = 'wake_word_hi_yutan_lite.tflite'\n",
        "\n",
        "model = tf.keras.models.load_model(base_path + 'best_model/wake_up_word_model')\n",
        "converter = lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "open(tflite_filename, 'wb').write(tflite_model)"
      ],
      "metadata": {
        "id": "54HAWoFDPoOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 추론 과정"
      ],
      "metadata": {
        "id": "q3vFUtQZRCN1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 기본 형태\n",
        "import pyaudio\n",
        "import numpy as np\n",
        " \n",
        "CHUNK = 2**10  # 음성 데이터 불러올때, 한번에 몇개의 정수를 불러올지\n",
        "RATE = 44100   # 음성 데이터의 sampleing rate , mfcc 에 나오는 거라 다른거니까 구분 해두기\n",
        "\n",
        "# 음성 데이터 스트리을 여는 코드\n",
        "\"\"\"\n",
        "foramt : 비트 깊이를 설정 ,   여기서는 16bit가 된다\n",
        "input : 우리가 지금 열려고 하는 것이기 떄문에 True\n",
        "frames_per_buffer : 한번에 몇개의 정수를 불러올지\n",
        "input_device_index : 원하는 입력 장치의 번호 (이거 없으면 자동으로 설정 해준다..)\n",
        "\"\"\"\n",
        "p=pyaudio.PyAudio()\n",
        "stream=p.open(format=pyaudio.paInt16,channels=1,rate=RATE,input=True,\n",
        "              frames_per_buffer=CHUNK,input_device_index=2)\n",
        " \n",
        "# 음성 데이터를 입력받아 출력하는 소스\n",
        "while(True):\n",
        "    data = np.fromstring(stream.read(CHUNK),dtype=np.int16)\n",
        "    print(int(np.average(np.abs(data))))\n",
        " \n",
        "stream.stop_stream()\n",
        "stream.close()\n",
        "p.terminate()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "Dztxh2RURmNs",
        "outputId": "7dfbfcd6-dbfb-479d-c3b8-b7f226c079f5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-457e60f56109>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpyaudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyaudio'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Connect a resistor and LED to board pin 8 and run this script.\n",
        "Whenever you say \"stop\", the LED should flash briefly\n",
        "\"\"\"\n",
        "\n",
        "import sounddevice as sd\n",
        "import numpy as np\n",
        "import scipy.signal\n",
        "import timeit\n",
        "import python_speech_features\n",
        "import RPi.GPIO as GPIO\n",
        "\n",
        "from tflite_runtime.interpreter import Interpreter\n",
        "\n",
        "# Parameters\n",
        "debug_time = 1\n",
        "debug_acc = 0\n",
        "led_pin = 8\n",
        "word_threshold = 0.5\n",
        "rec_duration = 0.5 # 기동어 말 평균 길이로 하면 될듯 함\n",
        "window_stride = 0.5 # 이거는 유지 해주기\n",
        "sample_rate = 48000\n",
        "resample_rate = 8000\n",
        "num_channels = 1\n",
        "num_mfcc = 40\n",
        "model_path = base_path + 'wake_word_hi_yutan_lite.tflite'\n",
        "\n",
        "# Sliding window\n",
        "window = np.zeros(int(rec_duration * resample_rate) * 2)\n",
        "\n",
        "# GPIO \n",
        "GPIO.setwarnings(False)\n",
        "GPIO.setmode(GPIO.BOARD)\n",
        "GPIO.setup(8, GPIO.OUT, initial=GPIO.LOW)\n",
        "\n",
        "# Load model (interpreter)\n",
        "interpreter = Interpreter(model_path)\n",
        "interpreter.allocate_tensors()\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "print(input_details)\n",
        "\n",
        "# Decimate (filter and downsample)\n",
        "def decimate(signal, old_fs, new_fs):\n",
        "    \n",
        "    # Check to make sure we're downsampling\n",
        "    if new_fs > old_fs:\n",
        "        print(\"Error: target sample rate higher than original\")\n",
        "        return signal, old_fs\n",
        "    \n",
        "    # We can only downsample by an integer factor\n",
        "    dec_factor = old_fs / new_fs\n",
        "    if not dec_factor.is_integer():\n",
        "        print(\"Error: can only decimate by integer factor\")\n",
        "        return signal, old_fs\n",
        "\n",
        "    # Do decimation\n",
        "    resampled_signal = scipy.signal.decimate(signal, int(dec_factor))\n",
        "\n",
        "    return resampled_signal, new_fs\n",
        "\n",
        "# This gets called every 0.5 seconds\n",
        "def sd_callback(rec, frames, time, status):\n",
        "\n",
        "    GPIO.output(led_pin, GPIO.LOW)\n",
        "\n",
        "    # Start timing for testing\n",
        "    start = timeit.default_timer()\n",
        "    \n",
        "    # Notify if errors\n",
        "    if status:\n",
        "        print('Error:', status)\n",
        "    \n",
        "    # Remove 2nd dimension from recording sample\n",
        "    rec = np.squeeze(rec)\n",
        "    \n",
        "    # Resample\n",
        "    rec, new_fs = decimate(rec, sample_rate, resample_rate)\n",
        "    \n",
        "    # Save recording onto sliding window\n",
        "    window[:len(window)//2] = window[len(window)//2:]\n",
        "    window[len(window)//2:] = rec\n",
        "\n",
        "    # Compute features\n",
        "    mfccs = python_speech_features.base.mfcc(window, \n",
        "                                        samplerate=new_fs,\n",
        "                                        winlen=0.256,\n",
        "                                        winstep=0.050,\n",
        "                                        numcep=num_mfcc,\n",
        "                                        nfilt=26,\n",
        "                                        nfft=2048,\n",
        "                                        preemph=0.0,\n",
        "                                        ceplifter=0,\n",
        "                                        appendEnergy=False,\n",
        "                                        winfunc=np.hanning)\n",
        "    mfccs = mfccs.transpose()\n",
        "\n",
        "    # Make prediction from model\n",
        "    in_tensor = np.float32(mfccs.reshape(1, mfccs.shape[0], mfccs.shape[1], 1))\n",
        "    interpreter.set_tensor(input_details[0]['index'], in_tensor)\n",
        "    interpreter.invoke()\n",
        "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "    val = output_data[0][0]\n",
        "    if val > word_threshold:\n",
        "        print('stop')\n",
        "        GPIO.output(led_pin, GPIO.HIGH)\n",
        "\n",
        "    if debug_acc:\n",
        "        print(val)\n",
        "    \n",
        "    if debug_time:\n",
        "        print(timeit.default_timer() - start)\n",
        "\n",
        "# Start streaming from microphone\n",
        "with sd.InputStream(channels=num_channels,\n",
        "                    samplerate=sample_rate,\n",
        "                    blocksize=int(sample_rate * rec_duration),  # 1초에 프레임 * 녹화 하는 기간\n",
        "                    callback=sd_callback):\n",
        "    while True:\n",
        "        pass"
      ],
      "metadata": {
        "id": "PR2BRCGCWHL3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}