{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wake_up_word_all",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyObsxN3PNglFnkA3tTclBnN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yutan0565/Wake-up-word-Tensorflow/blob/main/Wake_up_word_all.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 학습 준비"
      ],
      "metadata": {
        "id": "eL10wX1siLGx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaIMW3_FdLEV",
        "outputId": "55180386-cbac-410f-c864-4e98b154fe32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python_speech_features\n",
            "  Downloading python_speech_features-0.6.tar.gz (5.6 kB)\n",
            "Building wheels for collected packages: python-speech-features\n",
            "  Building wheel for python-speech-features (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-speech-features: filename=python_speech_features-0.6-py3-none-any.whl size=5888 sha256=3a8c4dd09abfcd7b5a2e868e704aabf75e4bf9cbad5a0b3218410f6f20537c90\n",
            "  Stored in directory: /root/.cache/pip/wheels/b0/0e/94/28cd6afa3cd5998a63eef99fe31777acd7d758f59cf24839eb\n",
            "Successfully built python-speech-features\n",
            "Installing collected packages: python-speech-features\n",
            "Successfully installed python-speech-features-0.6\n"
          ]
        }
      ],
      "source": [
        "!pip install python_speech_features\n",
        "from os import listdir\n",
        "from os.path import isdir, join\n",
        "import librosa\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import python_speech_features"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MFCC 추출 해주기\n",
        "# https://blog.naver.com/PostView.nhn?isHttpsRedirect=true&blogId=sooftware&logNo=221661644808 참고\n",
        "def get_librosa_mfcc(filepath):\n",
        "  samplie_rate = 8000\n",
        "  sig, sr = librosa.core.load(filepath, samplie_rate)\n",
        "  mfccs = librosa.feature.mfcc(y = sig, sr = sr, hop_length =200, n_mfcc = 40, n_fft = 320 )\n",
        "  return mfccs\n",
        "\n",
        "# n_mfcc : 음성데이터를 어느 단위로 쪼갤지 (사람은 20 ~ 40 ms 까지는 음소가 바뀌지 못함), return 될 mfcc의 개수\n",
        "# n_fft : frame의 length = window size,   잘린 음석이 n_ftt보다 작으면 0으로 Padding 해줌, \n",
        "   #n_fft는 winddow size보다 크거나 같아야함\n",
        "   # n_ftt = 8000 * 0.040 = 320\n",
        "# hop_legth : window 얼마 만큼씩 움질일 것인가\n",
        "\n",
        "  # n_mfcc = 40\n",
        "  # hop_length = 200  # 8000 * 0.040\n",
        "  # N_FFT = 320    # 8000 * 0.040\n",
        "\n",
        "# 이거 기준으로 나눈 다음에 Mel값을 뽑아서 Feature로 사용하게 된다.  (  50%는 겹치게 분할을 진행)\n",
        "# 각각의 frame에 대해서 Hamming Window 적용해서 연속성 맞춰주기 - Default 설정임\n",
        "# 각 프레임에 대하여 Fourier Transform 적용해서(FFT) 주파서 성분 알아내기\n",
        "# Mel Filter Banb(삶귀처럼, 주파수 증가할수록 큰 삼각형 filter가 생각다고 생각하기)\n",
        "# 여기까지하면 Mel-Spectrogram Feature가 추출된다.\n",
        "\n",
        "# Mel-Spectrogram 을 압축해서 표현해주는 DCT 연산 수행 -> Discrete Cosine Transform\n"
      ],
      "metadata": {
        "id": "RwAiwzW6oNC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터가 저장되어 있는 경로 ( class 별로 묶여 있는 곳)\n",
        "dataset_path = './custum_dataset'\n",
        "\n",
        "# 폴더 안에 들어 있는 폴더명(class 이름 확인)\n",
        "for name in listdir(dataset_path): \n",
        "  if isdir( \"/\".join( [dataset_path,name ])) :  # 폴더가 존재 한다면\n",
        "    print(name)\n",
        "\n",
        "# 폴더명 = target ,  target이 들어가 있는 list 생성\n",
        "target_list = [ name for name in listdir(dataset_path) if isdir(\"/\".join( [dataset_path,name ]))]\n",
        "target_list.remove('_background_noise_')  # 배경음 제거 해주기\n",
        "print(target_list)\n",
        "\n",
        "# filname, 을 쪽 모아서,\n",
        "filenames = []\n",
        "y = []\n",
        "for index, target in enumerate(target_list):\n",
        "    print('/'.join([dataset_path, target]))  # class 에 맞는 폴더 이름 넣어주기\n",
        "    filenames.append(listdir('/'.join([dataset_path, target])))\n",
        "    y.append(np.ones(len(filenames[index])) * index) \n",
        "\n",
        "# 하나로 쭉 나열 하기\n",
        "filenames = [item for sublist in filenames for item in sublist]\n",
        "y = [item for sublist in y for item in sublist]\n",
        "\n",
        "# file 모아둔거 한번 섞어 주기\n",
        "filenames_y = list(zip(filenames, y))\n",
        "random.shuffle(filenames_y)\n",
        "filenames, y = zip(*filenames_y)\n",
        "\n",
        "# train, valid, test 나눠 주기\n",
        "val_ratio = 0.1\n",
        "test_ratio = 0.2\n",
        "\n",
        "val_set_size = int(len(filenames) * val_ratio)\n",
        "test_set_size = int(len(filenames) * test_ratio)\n",
        "\n",
        "filenames_val = filenames[:val_set_size]\n",
        "filenames_test = filenames[val_set_size:(val_set_size + test_set_size)]\n",
        "filenames_train = filenames[(val_set_size + test_set_size):]\n",
        "\n",
        "y_val = y[:val_set_size]\n",
        "y_test = y[val_set_size:(val_set_size + test_set_size)]\n",
        "y_train = y[(val_set_size + test_set_size):]\n",
        "\n"
      ],
      "metadata": {
        "id": "iigZ1Z0diKbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "a7aOfxFvoM_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Ir7V_q_VoNFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gNjK8_proNIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "iOdWs4rVoNX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "eFsT1UyyoNbG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MFCC 를 만들어 주는데 있어서 필요한 변수\n",
        "target_list = all_targets\n",
        "feature_sets_file = 'all_targets_mfcc_sets.npz'\n",
        "perc_keep_samples = 1.0 # 몇퍼센트의 샘플을 사용 할 것인가 (딱히 필요 없는거 같음))\n",
        "val_ratio = 0.1\n",
        "test_ratio = 0.1\n",
        "\n",
        "# 1초에 8000 개의 샘플이 들어감  # 고주파가 사라짐\n",
        "# 원형은 유지하지만, samplie의 개수가 줄어들임\n"
      ],
      "metadata": {
        "id": "JqwH41Ulk1HH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 전처리 - MFCC"
      ],
      "metadata": {
        "id": "ZEn6cxYsiPDp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 학습"
      ],
      "metadata": {
        "id": "XVQZDw7giaeS"
      }
    }
  ]
}